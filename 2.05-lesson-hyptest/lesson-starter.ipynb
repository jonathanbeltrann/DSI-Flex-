{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "_Authors: Tim Book (DC), Matt Brems (DC), et. al_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Define the null and alternative hypotheses.\n",
    "- Perform a two-sample t-test.\n",
    "- Define the t-statistics and p-value.\n",
    "- List the steps of hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.1-cp39-cp39-macosx_10_15_x86_64.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25 in /Users/jonathanbeltran/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jonathanbeltran/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (1.21.2)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 23.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3 in /Users/jonathanbeltran/opt/miniconda3/lib/python3.9/site-packages (from statsmodels) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jonathanbeltran/opt/miniconda3/lib/python3.9/site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/jonathanbeltran/opt/miniconda3/lib/python3.9/site-packages (from pandas>=0.25->statsmodels) (2021.3)\n",
      "Requirement already satisfied: six in /Users/jonathanbeltran/opt/miniconda3/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.2 statsmodels-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in our libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Hypothesis Testing\n",
    "\n",
    "In the real world, we like to make **data-driven decisions$^{\\text{TM}}$**!\n",
    "- In order to make these decisions, though, we need to collect some data.\n",
    "- We take this data, put it into a \"box,\" which gives us a statisticall powered yes-or-no decision.\n",
    "- This \"box\" is hypothesis testing.\n",
    "- **Hypothesis testing is a mathematically rigorous way of making yes-or-no decisions!**\n",
    "\n",
    "Hypothesis testing is a little more complicated than that, but not much!\n",
    "\n",
    "### Hypothesis Testing with Puppies\n",
    "\n",
    "[This example is pulled liberally from Cassie Kozyrkov's Medium post.](https://hackernoon.com/explaining-p-values-with-puppies-af63d68005d0)\n",
    "\n",
    "Let's say that we come home at the end of the day to find some unspooled toilet paper.\n",
    "\n",
    "<img src=\"./images/pug_toilet_paper.jpg\" alt=\"doggo\" width=\"600\"/>\n",
    "\n",
    "We need to make a **data-driven** decision: Do we yell at our dog? \n",
    "\n",
    "Our possibilities are:\n",
    "- Yes, we yell at our dog.\n",
    "- No, we don't yell at our dog.\n",
    "\n",
    "Let's assume that our dog is innocent. Being good data scientists, we want to gather data, then use this data to make a decision.\n",
    "- We check to see if the bathroom window is open or closed.\n",
    "    - If it's open, maybe a gust of wind caused the toilet paper to unravel.\n",
    "    - If it's closed, then something else caused the toilet paper to unravel.\n",
    "- We check the thermostat to see if we left the heating/air conditioning on.\n",
    "    - If you left it on, maybe the floor vent in the bathroom caused the toilet paper to unravel.\n",
    "    - If it's turned off, then the floor vent couldn't have caused the toilet paper to unravel.\n",
    "- We text your sibling to see if they brought our niece over.\n",
    "    - If they came over, maybe our niece unraveled the toilet paper.\n",
    "    - If they didn't come over, then our niece couldn't have unraveled the toilet paper.\n",
    "\n",
    "Once you're done \"gathering your data,\" you make a decision.\n",
    "- If there's enough evidence to accept that our dog is guilty, then we'll yell at our dog.\n",
    "- If there's not enough evidence to say that our dog is guilty, then we'll just cuddle with our dog.\n",
    "\n",
    "We just walked through a hypothesis test! We had two potential decisions, we gathered data, and used this data to make a decision.\n",
    "\n",
    "> **Note that we only deem our dog guilty or not guilty. The dog is never pronounced innocent! Just like the U.S. court system, hypothesis testing works this way too.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing: A Drug Efficacy Example\n",
    "\n",
    "---\n",
    "\n",
    "Say we are testing the efficacy of a new drug:\n",
    "\n",
    "- We randomly select 50 people to be in the control group and 50 people to recieve the treatment.\n",
    "    - In the context of experiments, we often talk about the \"control\" group and the \"experimental\" or \"treatment\" group. In our example, the control group is the one given the old drug (the one currently on the market) and the treatment group is the one given the actual drug. \n",
    "    - In other experiments, the control group is the one that receives no treatment. There can be a placebo group as well, which is one that receives a false treatment. **Is this ethical in this scenario?**\n",
    "- We are interested in the average difference in blood pressure levels between the treatment and control groups.\n",
    "- We know our sample is selected from a broader, unknown population pool.\n",
    "- We can imagine that, in a hypothetical parallel world, we could have ended up with a different random sample of subjects from the population pool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='null-hypothesis'></a>\n",
    "\n",
    "### The \"Null\" Hypothesis\n",
    "\n",
    "---\n",
    "\n",
    "The **null hypothesis** is the \"status quo\" hypothesis that you wish to prove wrong. We typically denote the null hypothesis with $H_0$.\n",
    "- In our dog example, we assume that our dog is innocent.\n",
    "- In our drug efficacy experiment example, our null hypothesis is that there is no difference in blood pressure between a subject taking a placebo and and one taking the treatment drug.\n",
    "\n",
    "> $H_0:$ The average difference in blood pressure between treatment and control groups is zero.\n",
    "\n",
    "Or, as it's properly written:\n",
    "\n",
    "> $H_0: \\mu_\\text{trt} = \\mu_\\text{ctrl}$\n",
    "\n",
    "Or, as it's often written:\n",
    "\n",
    "> $H_0: \\mu_\\text{trt} - \\mu_\\text{ctrl} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='alternative-hypothesis'></a>\n",
    "\n",
    "### The \"Alternative Hypothesis\"\n",
    "\n",
    "---\n",
    "\n",
    "The **alternative hypothesis** is the outcome of the experiment that we hope to show. It's the opposite of our null hypothesis!\n",
    "- In our dog example, the alternative hypothesis is that our dog is guilty of unspooling the toilet paper.\n",
    "- In our drug efficacy experiment example, the alternative hypothesis is that there is in fact an average difference in blood pressure between the treatment and control groups. \n",
    "\n",
    "> $H_A:$ The parameter of interest — our average difference between treatment and control — is not zero.\n",
    "\n",
    "Or, in math:\n",
    "\n",
    "> $H_A: \\mu_\\text{trt} \\ne \\mu_\\text{ctrl}$\n",
    "\n",
    "Again, we usually write\n",
    "\n",
    "> $H_A: \\mu_\\text{trt} - \\mu_\\text{ctrl} \\ne 0$\n",
    "\n",
    "**NOTE:** The null and alternative hypotheses are concerned with the true values, or, in other words, the **parameter of the overall population**. Through hypothesis testing, we will make an **inference** (a decision) about this population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is it written like this? $\\mu$ vs $\\bar{x}$\n",
    "(THREAD) Can you remind me what a *population parameter* is?\n",
    "\n",
    "(THREAD) Can you remind me what a *sample statistic* is?\n",
    "\n",
    "Population parameters are often denoted with Greek letters. It would make no sense to conduct a hypothesis test with sample statistics, since they differ with each experiment, and you don't need to hypothesize about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the $t$-Test\n",
    "\n",
    "---\n",
    "\n",
    "In our dog example, we gathered data in a way that's different from how we'll usually gather data in order to make a decision.\n",
    "\n",
    "Say that, in our drug experiment, we measure the following results:\n",
    "\n",
    "- The 50 subjects in the control group have an average systolic blood pressure of 121.38.\n",
    "- The 50 subjects in the experimental/treatment group have an average systolic blood pressure of 111.56.\n",
    "\n",
    "The difference between experimental and control samples is -9.82 points. \n",
    "\n",
    "**But**, with only 50 subjects in each sample, how confident can we be that this measured difference is real? Do we have enough evidence to say that the population average blood pressure is different between these two groups?\n",
    "\n",
    "We can perform what is known as a **t-test** to evaluate this. (A $t$-test is one of many, many types of hypothesis tests.)\n",
    "\n",
    "Four steps to hypothesis testing:\n",
    "1. Construct a null hypothesis that you want to contradict and its complement, the alternative hypothesis.\n",
    "2. Specify a level of significance.\n",
    "3. Calculate your test statistic.\n",
    "4. Find your $p$-value and make a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bp    group\n",
       "0  166  control\n",
       "1  165  control\n",
       "2  120  control\n",
       "3   94  control\n",
       "4  104  control"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = pd.read_csv(\"data/blood-pressure.csv\")\n",
    "bp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the blood pressure data into two separate groups\n",
    "# (this is how we'll need it for a SciPy t-test)\n",
    "control_grp =bp.loc[bp['group'] == 'control', :]\n",
    "\n",
    "treatment_grp = bp.loc[bp['group'] == 'treatment', :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bp    111.56\n",
      "dtype: float64\n",
      "bp    121.38\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/85/gfsz06392cx1589spz1jvvtc0000gn/T/ipykernel_31261/1454921055.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(treatment_grp.mean())\n",
      "/var/folders/85/gfsz06392cx1589spz1jvvtc0000gn/T/ipykernel_31261/1454921055.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(control_grp.mean())\n"
     ]
    }
   ],
   "source": [
    "# Print the average of the control and experimental groups.\n",
    "print(treatment_grp.mean())\n",
    "print(control_grp.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='likelihood-data'></a>\n",
    "\n",
    "### Step 1: Construct the null and alternative hypotheses\n",
    "\n",
    "---\n",
    "\n",
    "For our experiment, we will set up a null hypothesis and an alternative hypothesis:\n",
    "\n",
    "$H_0:$ The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is 0.\n",
    "\n",
    "$H_A:$ The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is NOT 0.\n",
    "\n",
    "### Formally:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H_0: & \\mu_\\text{trt} = \\mu_\\text{ctrl} \\\\\n",
    "H_A: & \\mu_\\text{trt} \\ne \\mu_\\text{ctrl} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Recall, our measured difference is $\\bar{x}_\\text{trt} - \\bar{x}_\\text{ctrl} = -9.82$\n",
    "\n",
    "Written out using probability notation, we want to know:\n",
    "\n",
    "### $$P(\\text{data}\\;|\\;H_0 \\text{ true})$$\n",
    "\n",
    "**What is the probability that we observed this data, assuming that our null hypothesis is true?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Specify a level of significance\n",
    "\n",
    "If we assume that our null hypothesis is true, and the probability of observing the data we observed is \"small,\" then our data does not support our null hypothesis. \n",
    "\n",
    "**But how \"small\" is small enough?**\n",
    "\n",
    "This is set by our level of significance, which we call $\\alpha$.\n",
    "\n",
    "Typically (and arbitrarily) the value $\\alpha=0.05$ is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculating your Test Statistic\n",
    "\n",
    "---\n",
    "\n",
    "Remember that hypothesis testing is a \"box\" where the inputs are our data and the outputs allow us to make our decision? Well, in this \"box,\" we are calculating $P(\\text{data}\\;|\\;H_0 \\text{ true})$.\n",
    "\n",
    "When comparing two means, the **t-statistic** (based on the [Student's $t$-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution)) is a classic way to quantify the difference between groups. In essence, our $t$-statistic is a standardized version of the difference between groups.\n",
    "\n",
    "Luckily, our computer will do this for us!\n",
    "\n",
    "---\n",
    "\n",
    "<details><summary>Want the mathematical details of the calculation of the t-statistic?</summary>\n",
    "When comparing the difference between groups, we can calculate the two-sample t-statistic like so:\n",
    "\n",
    "### $$t = \\frac{\\bar{x}_E - \\bar{x}_C}{\\sqrt {s^2 \\Big(\\frac{1}{n_E} + \\frac{1}{n_C}\\Big)}}$$\n",
    "\n",
    "In our example, $\\bar{x}_E$ is the mean of our experimental group's sample measurements and $\\bar{x}_C$ is the mean of our control group's sample measurements.\n",
    "\n",
    "$n_E$ and $n_C$ are the number of observations in each group. \n",
    "\n",
    "The $s^2$ denotes our *sample variance*. In this version of the t-test, we are assuming equal variances in our experimental and control groups in the overall population. There is another way to calculate the t-test where equal variance is not assumed, but, in our case, it is a reasonable assumption.\n",
    "\n",
    "The sample variance is calculated like so:\n",
    "\n",
    "### $$ s^2 = \\frac{\\sum_{i=1}^{n_E} (x_i - \\bar{x}_E)^2 + \\sum_{j=1}^{n_C} (x_j - \\bar{x}_C)^2}{ n_E + n_C -2} $$\n",
    "\n",
    "This combines the variance of the two groups' measurements into a single pooled metric. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR What are we doing?\n",
    "\n",
    "**GOAL:** To tell whether or not our new treatment is effective. We define \"effective\" as whether or not those who get the treatment see lower systolic blood pressure, on average.\n",
    "\n",
    "To do this, we follow the following steps to carry out a **hypothesis test**:\n",
    "\n",
    "1. Set up null and alternative hypotheses. Remember, ours was this:\n",
    "\n",
    "$$ H_0: \\mu_\\text{trt} - \\mu_\\text{ctrl} = 0 $$\n",
    "$$ H_A: \\mu_\\text{trt} - \\mu_\\text{ctrl} \\ne 0 $$\n",
    "\n",
    "2. Decide on a significance level. $\\alpha = 0.05$ is a typical choice.\n",
    "3. Decide on a hypothesis test. There are a million of them. In this case, we're testing the difference between two means, which is a great time to use a **two-sample $t$-test**.\n",
    "\n",
    "> The two-sample (independent) $t$-test tests whether or not two population means differ.\n",
    "\n",
    "4. After carrying out this hypothesis test, we'll see if our data provide enough evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do it!\n",
    "Uh... how? What function do I use? Help me, Google!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct our t-test.\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/85/gfsz06392cx1589spz1jvvtc0000gn/T/ipykernel_31261/2786074226.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttest_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_grp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment_grp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mttest_ind\u001b[0;34m(a, b, axis, equal_var, nan_policy, permutations, random_state, alternative, trim)\u001b[0m\n\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6133\u001b[0;31m             \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6134\u001b[0m             \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6135\u001b[0m             \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   3721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3723\u001b[0;31m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0m\u001b[1;32m   3724\u001b[0m                          **kwargs)\n\u001b[1;32m   3725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n\u001b[0m\u001b[1;32m    223\u001b[0m                                  subok=False)\n\u001b[1;32m    224\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "stats.ttest_ind(control_grp, treatment_grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p-value'></a>\n",
    "\n",
    "### Step 4: The P-Value\n",
    "\n",
    "---\n",
    "\n",
    "Remember that our goal of doing all of this work is to make a decision? Well, using our $t$-statistic, we can generate a **p-value**.\n",
    "\n",
    "> **The p-value is the probability that, given that the null hypothesis $H_0$ is true, we could have ended up with a statistic at least as extreme as the one we got.**\n",
    "\n",
    "We have measured a difference in blood pressure of -9.82 between the experimental and control groups. We then calculated a $t$-statistic associated with this difference of -1.89. In our specific example:\n",
    "\n",
    "> The p-value is the probability that, assuming there is truly no difference in blood pressure between treatment and control conditions (i.e., no effect of the drug), we get results that yield a t-statistic more extreme than -1.89."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do we make the decision? *(This will show up in interviews!)*\n",
    "\n",
    "Remember that $\\alpha$ is our level of significance.\n",
    "\n",
    "- If $p\\text{-value} < \\alpha$, then there is evidence to reject the null hypothesis, so you accept that $H_0$ is incorrect and therefore $H_A$ is correct.\n",
    "    - i.e., a statisically significant difference between the two groups!\n",
    "    - This is like saying there is enough evidence to say our dog isn't innocent... so we say our dog is guilty.\n",
    "- If $p\\text{-value} \\ge \\alpha$, then there is insufficient evidence to reject the null hypothesis and you cannot accept that either $H_0$ or $H_A$ is correct.\n",
    "    - i.e., there is no statistical difference between your two groups.\n",
    "    - This is like saying there is not enough evidence to say our dog isn't innocent. We can't totally determine that our dog is innocent, but we haven't determined that our dog is guilty, either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So.... what is our decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for good measure... what's the opposite opinion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: HOW do we interpret statsmodels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in house data, print first few rows\n",
    "houses = pd.read_csv('data/houses-norm.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit OLS model to house data\n",
    "X = houses[['sqft', 'bedrooms', 'age']]\n",
    "y = houses['price']\n",
    "\n",
    "\n",
    "X = sm.add_constant(X, prepend=True)\n",
    "\n",
    "results = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   39.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Dec 2021</td> <th>  Prob (F-statistic):</th> <td>2.12e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:58:42</td>     <th>  Log-Likelihood:    </th> <td> -45.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    47</td>      <th>  AIC:               </th> <td>   99.28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    43</td>      <th>  BIC:               </th> <td>   106.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    0.9245</td> <td>    0.449</td> <td>    2.060</td> <td> 0.045</td> <td>    0.019</td> <td>    1.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft</th>     <td>    1.3933</td> <td>    0.150</td> <td>    9.305</td> <td> 0.000</td> <td>    1.091</td> <td>    1.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th> <td>   -0.0862</td> <td>    0.156</td> <td>   -0.551</td> <td> 0.584</td> <td>   -0.402</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>      <td>   -0.0081</td> <td>    0.043</td> <td>   -0.188</td> <td> 0.852</td> <td>   -0.095</td> <td>    0.079</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.841</td> <th>  Durbin-Watson:     </th> <td>   1.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.147</td> <th>  Jarque-Bera (JB):  </th> <td>   2.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.552</td> <th>  Prob(JB):          </th> <td>   0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.444</td> <th>  Cond. No.          </th> <td>    28.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.733\n",
       "Model:                            OLS   Adj. R-squared:                  0.715\n",
       "Method:                 Least Squares   F-statistic:                     39.38\n",
       "Date:                Sat, 11 Dec 2021   Prob (F-statistic):           2.12e-12\n",
       "Time:                        14:58:42   Log-Likelihood:                -45.641\n",
       "No. Observations:                  47   AIC:                             99.28\n",
       "Df Residuals:                      43   BIC:                             106.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.9245      0.449      2.060      0.045       0.019       1.830\n",
       "sqft           1.3933      0.150      9.305      0.000       1.091       1.695\n",
       "bedrooms      -0.0862      0.156     -0.551      0.584      -0.402       0.229\n",
       "age           -0.0081      0.043     -0.188      0.852      -0.095       0.079\n",
       "==============================================================================\n",
       "Omnibus:                        3.841   Durbin-Watson:                   1.819\n",
       "Prob(Omnibus):                  0.147   Jarque-Bera (JB):                2.771\n",
       "Skew:                           0.552   Prob(JB):                        0.250\n",
       "Kurtosis:                       3.444   Cond. No.                         28.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print summary\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the statsmodels results\n",
    "\n",
    "![](images/statsmodels1.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](images/statsmodels2.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](images/statsmodels3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing our OLS coefficients\n",
    "By far the most common place we'll see hypothesis testing is in the context of linear regression coefficients. Let's read in some data and use `statsmodels` to conduct a quick linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>angle</th>\n",
       "      <th>chord_len</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thickness</th>\n",
       "      <th>db</th>\n",
       "      <th>junk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "      <td>-2.114732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "      <td>-0.641775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "      <td>1.794972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "      <td>-0.559394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "      <td>-0.401292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq  angle  chord_len  velocity  thickness       db      junk\n",
       "0   800    0.0     0.3048      71.3   0.002663  126.201 -2.114732\n",
       "1  1000    0.0     0.3048      71.3   0.002663  125.201 -0.641775\n",
       "2  1250    0.0     0.3048      71.3   0.002663  125.951  1.794972\n",
       "3  1600    0.0     0.3048      71.3   0.002663  127.591 -0.559394\n",
       "4  2000    0.0     0.3048      71.3   0.002663  127.461 -0.401292"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a NASA dataset of airfoils at various wind tunnel speeds and angles of attack.\n",
    "# Their goal was to minimize noise (measured in db)\n",
    "df = pd.read_csv(\n",
    "    \"data/airfoil_self_noise.dat\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"freq\", \"angle\", \"chord_len\", \"velocity\", \"thickness\", \"db\"]\n",
    ")\n",
    "df[\"junk\"] = np.random.randn(df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X,y\n",
    "\n",
    "X = df[['angle', 'chord_len', 'velocity', 'thickness', 'junk']]\n",
    "#other way \n",
    "# X = df.drop('db', axis=1)\n",
    "y = df['db']\n",
    "\n",
    "X = sm.add_constant(X, prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>db</td>        <th>  R-squared:         </th> <td>   0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   82.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 Dec 2021</td> <th>  Prob (F-statistic):</th> <td>1.57e-76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:16:48</td>     <th>  Log-Likelihood:    </th> <td> -4852.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1503</td>      <th>  AIC:               </th> <td>   9717.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1497</td>      <th>  BIC:               </th> <td>   9749.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>  128.2322</td> <td>    0.666</td> <td>  192.527</td> <td> 0.000</td> <td>  126.926</td> <td>  129.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>angle</th>     <td>   -0.1402</td> <td>    0.048</td> <td>   -2.915</td> <td> 0.004</td> <td>   -0.234</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chord_len</th> <td>  -26.8611</td> <td>    2.043</td> <td>  -13.150</td> <td> 0.000</td> <td>  -30.868</td> <td>  -22.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>velocity</th>  <td>    0.0587</td> <td>    0.010</td> <td>    5.750</td> <td> 0.000</td> <td>    0.039</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thickness</th> <td> -158.3545</td> <td>   19.106</td> <td>   -8.288</td> <td> 0.000</td> <td> -195.832</td> <td> -120.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>      <td>    0.0390</td> <td>    0.158</td> <td>    0.247</td> <td> 0.805</td> <td>   -0.271</td> <td>    0.349</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>20.439</td> <th>  Durbin-Watson:     </th> <td>   0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  18.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.228</td> <th>  Prob(JB):          </th> <td>8.42e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.696</td> <th>  Cond. No.          </th> <td>6.49e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.49e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     db   R-squared:                       0.216\n",
       "Model:                            OLS   Adj. R-squared:                  0.213\n",
       "Method:                 Least Squares   F-statistic:                     82.36\n",
       "Date:                Sat, 11 Dec 2021   Prob (F-statistic):           1.57e-76\n",
       "Time:                        15:16:48   Log-Likelihood:                -4852.3\n",
       "No. Observations:                1503   AIC:                             9717.\n",
       "Df Residuals:                    1497   BIC:                             9749.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        128.2322      0.666    192.527      0.000     126.926     129.539\n",
       "angle         -0.1402      0.048     -2.915      0.004      -0.234      -0.046\n",
       "chord_len    -26.8611      2.043    -13.150      0.000     -30.868     -22.854\n",
       "velocity       0.0587      0.010      5.750      0.000       0.039       0.079\n",
       "thickness   -158.3545     19.106     -8.288      0.000    -195.832    -120.877\n",
       "junk           0.0390      0.158      0.247      0.805      -0.271       0.349\n",
       "==============================================================================\n",
       "Omnibus:                       20.439   Durbin-Watson:                   0.411\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.766\n",
       "Skew:                          -0.228   Prob(JB):                     8.42e-05\n",
       "Kurtosis:                       2.696   Cond. No.                     6.49e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.49e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit OLS model to data\n",
    "results = sm.OLS(y, X).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary statistics of model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "Notice the columns marked `t` and `P>|t|`. These are the $t$-statistics and $p$-values for the hypothesis test:\n",
    "\n",
    "$$\n",
    "H_0: \\beta_i = 0 \\\\\n",
    "H_A: \\beta_i \\ne 0\n",
    "$$\n",
    "\n",
    "(THREAD) In your own words, what would it mean if $\\beta_i = 0$ for one of these coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Law of Parsimony (aka: Occam's Razor)\n",
    "This is usually paraphrased as:\n",
    "> The simplest explanation for a phenomenon is usually the correct one.\n",
    "\n",
    "We don't want to overspecify our model. In our context, that means we want to avoid any potential overfitting. While we **never accept the null hypothesis**, the truth is, _some decision must be made_. Oftentimes, we drop variables from our model that do not have significant $p$-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Hypothesis Tests\n",
    "The goal of this lesson was to teach you, in general, how hypothesis testing works. We showed you what is probably the most common variety of hypothesis test: the $t$-test. However, there are kajillions of other ones out there. It's not worth our time to go over so many more of them, as they all have the same implementation and interpretation, just in different situations. Instead, here is a list of many of the \"big\" ones and when to use them:\n",
    "\n",
    "| Situation | Common hypothesis test | Example | Notes |\n",
    "| --- | --- | --- | --- |\n",
    "| Testing whether or not one mean is equal to a value | One-sample $t$-test | Do cars on a given road, on average, drive about 65mph? | |\n",
    "| Testing whether or not two means are equal to eachother | Two-sample $t$-test | Is the mean systolic blood pressure of people who receive Medicine A or Medicine B the same? | |\n",
    "| Testing whether or not paired observations have the same value | Paired $t$-test | Among heterosexual married couples, is the husband, on average, taller than the wife? | This is functionally the same as a one-sample $t$-test of the differences |\n",
    "| Testing whether or not three or more means are the same | One-way ANOVA test | Are base salaries upon graduation different for graduates of Penn State, Ohio State, and Michigan? | The ANOVA test has many variants |\n",
    "| Testing whether or not there is a relationship between two categorical variables | $\\chi^2$ test | Is there a relationship between home state and political affiliation? | |\n",
    "| Testing whether or not a given distribution is normally distributed | Kolmogorov-Smirnov Test | Testing whether or not model residuals are normally distributed. Useful for testing linear regression assumptions! | |\n",
    "| Testing whether or not one proportion is equal to a number | One-sample $z$-test | Testing whether or not a coin is fair (ie, testing $P(Heads) = 0.5$) | |\n",
    "| Testing whether or not two proportions are euqal | Two-sample $z$-test | Who is going to win an election? | Testing two or more proportions can be done better with a $\\chi^2$ test |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Four steps to hypothesis testing:\n",
    "1. Construct a null hypothesis that you want to contradict and its complement, the alternative hypothesis.\n",
    "2. Specify a level of significance.\n",
    "3. Calculate your test statistic.\n",
    "4. Find your $p$-value and make a conclusion."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
